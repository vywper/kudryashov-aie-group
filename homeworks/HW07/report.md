# HW07 – Report

> Файл: `homeworks/HW07/report.md`  
> Важно: не меняйте названия разделов (заголовков). Заполняйте текстом и/или вставляйте результаты.

## 1. Datasets

Вы выбрали 3 датасета из 4 (перечислите): 2, 3, 4.

### 1.1 Dataset A

- Файл: `data/S07-hw-dataset-02.csv`
- Размер: (8000, 4)
- Признаки: числовые
- Пропуски: нет
- "Подлости" датасета: нелинейная структура + выбросы + лишний шумовой признак.

### 1.2 Dataset B

- Файл: `data/S07-hw-dataset-03.csv`
- Размер: (10000, 33)
- Признаки: числовые
- Пропуски: нет
- "Подлости" датасета: кластеры разной плотности + фоновый шум

### 1.3 Dataset C

- Файл: `data/S07-hw-dataset-04.csv`
- Размер: (10000, 33)
- Признаки: 2 числовых, 2 категориальных
- Пропуски: есть (5915 по колонкам)
- "Подлости" датасета: высокая размерность + 2 категориальных признака + пропуски в числовых.

## 2. Protocol
В работе использовался единый и «честный» протокол unsupervised-кластеризации, одинаковый для всех датасетов, что позволяет корректно сравнивать алгоритмы между собой.

**Препроцессинг:**
Для всех числовых признаков применялся StandardScaler. Пропуски в числовых признаках заполнялись медианными значениями. Для датасетов с категориальными признаками (Dataset C) использовалось one-hot encoding.

*PCA:*
*Использовалась исключительно для визуализации (2D), не для обучения моделей.*

Подбор параметров осуществлялся перебором фиксированной сетки:

- *KMeans*

  - k_range = range(2, 10)

  - n_init ∈ {5, 10}


- *DBSCAN*

  - eps ∈ {0.3, 0.5, 0.7, 1.0}

  - min_samples ∈ {5, 10}

- *AgglomerativeClustering:*

  - k_range = range(2, 10)

  - linkage ∈ {"ward", "average"}

Для каждой конфигурации вычислялись три стандартные unsupervised-метрики:

- Silhouette score (максимизируется)

- Calinski–Harabasz index (максимизируется)

- Davies–Bouldin index (минимизируется)

Для выбора лучшей модели использовалась нормализация и суммарный скоринг этих метрик.

*Для DBSCAN метрики считались только по ненулевым (не-noise) объектам, дополнительно фиксировалась доля шума.*


## 3. Models

Для каждого датасета сравнивались следующие модели:
- **KMeans**
  - Подбор k
  - Подбор n_init
- **DBSCAN**
  - Подбор eps и min_samples
  - Анализ доли шума
- **Agglomerative Clustering**
  - Подбор числа кластеров k
  - Сравнение ward и average linkage
## 4. Results
### 4.1 Dataset A

Лучший метод: KMeans

Параметры: k=2, n_init=5

Метрики:

- Silhouette = 0.307

- Davies–Bouldin = 1.323

- Calinski–Harabasz = 3573

Итоговый скор: 1.946

Комментарий:
Несмотря на нелинейную структуру и выбросы, KMeans корректно выделил два доминирующих компактных кластера. DBSCAN оказался менее стабильным из-за чувствительности к выбору eps и наличия шума.

### 4.2 Dataset B

Лучший метод: KMeans

Параметры: k=3, n_init=10

Метрики:

- Silhouette = 0.316

- Davies–Bouldin = 1.158

- Calinski–Harabasz = 6957

Итоговый скор: 2.203

Комментарий:
Несмотря на различную плотность кластеров, после масштабирования данные хорошо аппроксимируются сферическими группами. DBSCAN терял значительную часть объектов в шуме, а Agglomerative давал менее стабильные разбиения.

### 4.3 Dataset C

Лучший метод: KMeans

Параметры: k=5, n_init=10

Метрики:

- Silhouette = 0.447

- Davies–Bouldin = 0.976

- Calinski–Harabasz = 5088

Итоговый скор: 2.654

Комментарий:
После импутации пропусков и кодирования категориальных признаков данные стали хорошо масштабируемыми. KMeans эффективно использовал агрегированную информацию высокой размерности.
Во всех датасетах значения метрик согласованы между собой и указывают на наличие осмысленной кластерной структуры, при этом различия в абсолютных значениях отражают сложность и «подлости» конкретных данных.

## 5. Analysis

### 5.1 Сравнение алгоритмов (важные наблюдения)

KMeans ломается, когда присутствует выраженная нелинейная структура, кластеры имеют сильно различную плотность, есть большой процент шума.

DBSCAN выигрывает на данных с чёткими плотностными кластерами, но крайне чувствителен к eps, плохо масштабируется в высокой размерности.

Agglomerative Clustering стабилен, но хуже масштабируется, часто уступает KMeans по всем трём метрикам.

### 5.2 Устойчивость (Dataset A)

Проведено 5 запусков KMeans с разными random_state.

Средний ARI = 0.998

Std ARI = 0.001

Вывод: решение устойчиво, кластеры воспроизводятся.

### 5.3 Интерпретация кластеров

Кластеры интерпретировались через анализ средних значений признаков. Для всех датасетов кластеры демонстрировали: чёткие различия по ключевым признакам и минимальные пересечения в PCA-проекции.

## 6. Conclusion

Unsupervised-протокол требует строгой фиксации шагов и метрик. Использование нескольких метрик одновременно играет важную роль в выявлении лучшего решения. Нормализация метрик позволяет объективно сравнивать модели.

KMeans остаётся сильным базовым алгоритмом при корректном препроцессинге.

DBSCAN эффективен, но нестабилен без точного подбора параметров.

Agglomerative Clustering стабилен, но хуже масштабируется, часто уступает KMeans по всем трём метрикам.

Визуализация (PCA) необходима для sanity-check результатов.
# Домашнее задание к семинару 05 (HW05)

Тема: линейные модели и честный ML-эксперимент (логистическая регрессия, бейзлайн, метрики).

HW05 относится к семинару **S05** и выполняется в личном репозитории студента, созданном на основе шаблона `aie-student-template`, в папке `homeworks/HW05/`.

---

## 1. Цель

Закрепить:

- базовые навыки работы с **линейными моделями** в `scikit-learn` (прежде всего – логистическая регрессия для бинарной классификации);
- умение строить и интерпретировать **простые бейзлайны** (`DummyClassifier`) и сравнивать их с моделями;
- навыки постановки **честного ML-эксперимента**: train/test-сплит, выбор набора признаков, подбор простых гиперпараметров;
- работу с **метриками качества модели** (accuracy, ROC-AUC; при желании – дополнительные метрики);
- оформление результатов эксперимента в виде аккуратного ноутбука с кодом и текстовыми выводами.

---

## 2. Задание

### 2.1. Структура для HW05

1. В корне репозитория должна быть папка `homeworks/` (создать, если её ещё нет).
2. Внутри `homeworks/` создать папку `HW05/`.
3. В папке `homeworks/HW05/` создать основной ноутбук `HW05.ipynb`.
4. Рекомендуется (но не строго обязательно) создать внутри `homeworks/HW05/` дополнительные подпапки для артефактов эксперимента:
   - `figures/` – для сохранения графиков (ROC-кривая, PR-кривая и т.п.);
   - `artifacts/` – по желанию, для сохранения таблиц с результатами, параметров моделей и т.д.

> Если структура уже частично создана на семинаре, убедитесь, что имена папок и файлов совпадают с указанными (регистр букв важен).

---

### 2.2. Учебный датасет `S05-hw-dataset.csv`

1. Использовать **учебный табличный датасет**, предоставленный преподавателем:
   - файл `S05-hw-dataset.csv` будет приложен к материалам семинара S05;
   - рекомендуется поместить его в папку `seminars/S05/` вашего репозитория или в любую другую осмысленную папку данных;
   - в ноутбуке `HW05.ipynb` путь к файлу должен быть **относительным** (без абсолютных путей к домашним каталогам).

2. Все данные в датасете **полностью синтетические** и не описывают реальных людей или реальные кредитные истории.

#### 2.2.1. Общая информация

- Каждая строка – условный клиент банка с набором финансовых и поведенческих признаков.
- Целевая переменная (`target`) – столбец `default`: факт дефолта по кредиту (1 – дефолт, 0 – нет).
- Размер датасета – порядка 3000 наблюдений (строк).
- Доля `default = 1` – около 40% (задача не идеально сбалансирована, но и не экстремально перекошена).

#### 2.2.2. Описание столбцов

В датасете содержатся следующие столбцы (набор может быть немного расширен, но смысл – такой):

- `client_id` – идентификатор клиента (целое число).  
  Используется только как технический ID, в модели его можно не использовать.

- `age` – возраст клиента (целое число, ~21-69 лет).

- `income` – годовой доход клиента (целое число в условных единицах, ~15 000-200 000).

- `years_employed` – стаж работы (количество полных лет, целое число).

- `credit_score` – условный кредитный скоринг (целое число, диапазон примерно 300-850).  
  Чем выше значение, тем «надёжнее» клиент.

- `debt_to_income` – отношение ежемесячных долговых платежей к доходу (вещественное число от 0 до 1).

- `num_credit_cards` – количество кредитных карт (целое число, обычно от 0 до 7).

- `num_late_payments` – количество просрочек платежей за некоторый период (целое число, от 0 и выше).

- `has_mortgage` – флаг наличия ипотеки (0 – нет, 1 – есть).

- `has_car_loan` – флаг наличия автокредита (0 – нет, 1 – есть).

- `savings_balance` – объём сбережений клиента (целое число, от 0 и выше, условные единицы).

- `checking_balance` – баланс на расчетном счёте (целое число, может быть отрицательным).

- `region_risk_score` – условный риск региона проживания клиента (вещественное число 0..1; чем больше, тем рискованнее).

- `phone_calls_to_support_last_3m` – количество обращений клиента в поддержку за последние 3 месяца (целое число).

- `active_loans` – количество активных займов (целое число).

- `customer_tenure_years` – сколько лет клиент обслуживается в этом банке (целое число).

- `default` – **целевой бинарный признак**: факт дефолта по кредиту (0/1).  
  Это **таргет**, который нужно предсказывать.

> Описание признаков даётся для понимания контекста. Это не отменяет необходимости сделать свой минимальный EDA и посмотреть на распределения, баланс классов и т.п.

---

### 2.3. Содержание ноутбука `HW05.ipynb` (основная часть)

В ноутбуке `homeworks/HW05/HW05.ipynb` необходимо выполнить следующие шаги.

#### 2.3.1. Загрузка данных и первичный анализ

1. Импортировать необходимые библиотеки:
   - `pandas` и, при необходимости, `numpy`;
   - модули из `scikit-learn`: `train_test_split`, `DummyClassifier`, `LogisticRegression`, `Pipeline`, `StandardScaler`, метрики (`accuracy_score`, `roc_auc_score` и т.п.);
   - при желании – `matplotlib`/`seaborn` для графиков.

2. Загрузить датасет `S05-hw-dataset.csv` в `pandas.DataFrame` с помощью `pd.read_csv`.

3. Вывести и проанализировать:
   - первые строки датасета (`head()`),
   - информацию о столбцах и типах (`info()`),
   - базовые описательные статистики для числовых признаков (`describe()` или аналог),
   - распределение целевого признака `default` (например, через `value_counts(normalize=True)`).

4. Кратко (несколько предложений) зафиксировать наблюдения:
   - сколько объектов и признаков в датасете;
   - есть ли явные аномалии (например, явно невозможные значения);
   - как распределён таргет (баланс классов).

#### 2.3.2. Подготовка признаков и таргета

1. Выделить матрицу признаков `X` и вектор таргета `y`:
   - таргет – столбец `default`;
   - в качестве признаков использовать все остальные осмысленные столбцы (кроме `client_id`, который можно удалить или не использовать в `X`).

2. При необходимости выполнить простую предобработку:
   - убедиться, что все используемые признаки числовые;
   - при желании можно явно проверить диапазоны (например, что `debt_to_income` в [0, 1]).

3. Никаких сложных преобразований (one-hot, генерация фич и т.п.) не требуется – цель HW05 в другом. По желанию, вы можете их добавить, но это не обязательно для зачёта.

#### 2.3.3. Train/Test-сплит и бейзлайн-модель

1. Разделить данные на обучающую и тестовую выборки:
   - использовать `train_test_split` из `sklearn.model_selection`;
   - разумное соотношение, например `test_size=0.2` или `0.25`;
   - важно: зафиксировать `random_state` (например, `random_state=42`), чтобы результаты были воспроизводимыми;
   - рекомендуется использовать `stratify=y`, чтобы сохранить баланс классов.

2. Построить **бейзлайн-модель** на основе `DummyClassifier`:
   - например, `strategy="most_frequent"` или `strategy="stratified"`;
   - обучить её на обучающей выборке (`fit(X_train, y_train)`).

3. Оценить бейзлайн по крайней мере по двум метрикам:
   - `accuracy` на тестовой выборке;
   - `ROC-AUC` на тестовой выборке (если используете `predict_proba` или `decision_function`).

4. Вывести значения метрик и коротко прокомментировать, что делает бейзлайн и почему важно иметь точку отсчёта.

#### 2.3.4. Логистическая регрессия и подбор гиперпараметров

1. Построить `Pipeline`, состоящий минимум из:
   - стандартизации признаков (`StandardScaler`);
   - логистической регрессии (`LogisticRegression`).

   Примерно в таком духе (код можно оформить по-своему):

   ```python
   pipe = Pipeline([
       ("scaler", StandardScaler()),
       ("logreg", LogisticRegression(max_iter=1000))
   ])
   ```

2. Подобрать параметр регуляризации `C` (и при желании ещё 1-2 параметра) с помощью:

   - либо `GridSearchCV`;
   - либо простого перебора в цикле по нескольким значениям `C` (например, `[0.01, 0.1, 1.0, 10.0]`).

3. Для лучшей найденной модели посчитать на тестовой выборке:

   - `accuracy`;
   - `ROC-AUC`;
   - по желанию: `precision`, `recall`, `f1`, confusion matrix.

4. (Рекомендуется) Построить хотя бы один график:

   - ROC-кривая **или** PR-кривая (для этого можно использовать функции из `sklearn.metrics` + `matplotlib`).

5. Сохранить хотя бы один график (например, ROC-кривую) в файл в папку `homeworks/HW05/figures/`.

#### 2.3.5. Сравнение бейзлайна и логистической регрессии, текстовые выводы

1. Свести результаты в компактный вид:

   - можно сделать небольшую табличку (например, `pandas.DataFrame`), где по строкам – модели (Dummy vs LogisticRegression), по столбцам – метрики;
   - либо просто аккуратно вывести все значения в текстовом виде.

2. В конце ноутбука написать **краткий текстовый отчёт** (5-10 предложений), в котором:

   - объяснить, чем бейзлайн отличается от логистической регрессии по качеству;
   - указать, насколько сильно выросла (или не выросла) `accuracy` и `ROC-AUC`;
   - при наличии нескольких значений `C` – прокомментировать, как изменение регуляризации влияло на качество;
   - сформулировать 2-3 простых вывода о том, какая модель кажется разумной для этой задачи и почему.

---

### 2.4. Опциональная часть (для желающих)

Эта часть **не обязательна** для зачёта, но может быть учтена как плюс.

Идеи для опциональной части:

1. **Дополнительные метрики и графики**

   - добавить PR-кривую и `average_precision_score`;
   - посчитать и интерпретировать `precision`, `recall`, `f1` для выбранного порога.

2. **Калибровка вероятностей**

   - использовать `CalibratedClassifierCV` для калибровки логистической регрессии;
   - сравнить калибровочные кривые (reliability plot) до и после калибровки;
   - текстом описать, стала ли модель «честнее» в прогнозировании вероятностей.

3. **Сравнение с другой моделью**

   - добавить ещё одну модель (например, `RandomForestClassifier` или `SVC`);
   - честно указать, какие параметры перебирались;
   - сравнить с логистической регрессией и бейзлайном.

---

## 3. Требования к структуре и именованию

Обязательная структура к дедлайну:

- в корне репозитория: папка `homeworks/`;
- внутри неё: папка `HW05/`;
- внутри папки `HW05/`:

  - основной ноутбук `HW05.ipynb`;
  - (рекомендуется) папка `figures/` с хотя бы одним сохранённым графиком.

Требования:

- названия папок и файлов должны быть **строго такими**, как указано выше (регистр букв имеет значение);
- ноутбук `HW05.ipynb` должен уметь корректно загрузить `S05-hw-dataset.csv` по относительному пути;
- код в ноутбуке должен выполняться **без ошибок** при последовательном запуске всех ячеек (при наличии стандартного окружения: `pandas`, `numpy`, `scikit-learn`, `matplotlib`/`seaborn`).

Опциональные артефакты (дополнительные графики, артефакты эксперимента) дополняют HW05, но не заменяют основную часть задания.

---

## 4. Критерии зачёта

Домашнее задание считается зачтённым, если:

1. В публичном репозитории студента присутствует папка `homeworks/HW05/` с файлом `HW05.ipynb`.

2. Ноутбук `HW05.ipynb` содержит:

   - корректную загрузку датасета `S05-hw-dataset.csv` в `pandas.DataFrame`;
   - первичный анализ данных: `head`, `info`, `describe` (или аналог) + анализ распределения таргета `default`;
   - выделение матрицы признаков `X` и таргета `y` (с исключением `client_id` из признаков);
   - разбиение данных на train/test с фиксированным `random_state` и осмысленными параметрами `test_size` и `stratify`;
   - реализацию бейзлайн-модели на основе `DummyClassifier` и вычисление хотя бы двух метрик (включая `accuracy`);
   - реализацию логистической регрессии в виде `Pipeline` (скейлер + модель) и подбор хотя бы одного гиперпараметра (`C`);
   - сравнение качества бейзлайна и логистической регрессии на тестовой выборке по `accuracy` и `ROC-AUC`;
   - краткий текстовый отчёт с выводами по результатам эксперимента.

3. Хотя бы один график (например, ROC-кривая) либо:

   - построен прямо в ноутбуке,
   - либо дополнительно сохранён в файл в структуре репозитория (`homeworks/HW05/figures/`).

4. Код выполняется без ошибок при последовательном запуске всех ячеек ноутбука.

Дополнительно поощряется (но не обязательно для зачёта):

- аккуратные подписи осей, легенд и заголовков графиков;
- использование дополнительных метрик и осмысленных графиков (PR-кривая, confusion matrix и т.п.);
- наличие опциональной части (калибровка, сравнение с другой моделью и т.д.);
- внятные и понятные текстовые комментарии, связывающие результаты метрик с логикой задачи.

---

## 5. Сроки и порядок сдачи

- Работа выполняется **индивидуально**.
- Дедлайн выполнения HW05 объявляется преподавателем отдельно (в чате/на портале курса).
- Фактом сдачи работы считается наличие к указанному дедлайну:

  - публичного репозитория студента;
  - структуры `homeworks/HW05/`;
  - файла `HW05.ipynb` с выполненным заданием по датасету `S05-hw-dataset.csv` (в актуальной версии ветки `main` или другой заранее оговорённой ветки).

Опциональные дополнения (дополнительные модели, калибровка и т.п.) учитываются как плюс, но не компенсируют отсутствие или критическую неполноту основной части HW05.
